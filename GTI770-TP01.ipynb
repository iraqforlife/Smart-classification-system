{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 1 : Extraction de primitives\n",
    "#### D√©partement du g√©nie logiciel et des technologies de l‚Äôinformation\n",
    "\n",
    "| √âtudiants             | ahmad al-taher - alta22109307                           |\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Syst√®mes intelligents et apprentissage machine |\n",
    "| Session               | automn 2018                                             |\n",
    "| Groupe                | 2                                                       |\n",
    "| Num√©ro du laboratoire | 00                                                      |\n",
    "| Professeur            | Herv√© Lombaert                                          |\n",
    "| Charg√© de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 20 sep 2018                                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2 as cv\n",
    "from scipy.misc import imread, imshow,face\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree, preprocessing\n",
    "import graphviz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "    def __init__(self, path,label, answer):\n",
    "        \"\"\"\n",
    "             The only construct is to build an object type image that has all the elements required to make a decision weather it is\n",
    "             a smooth or spiral galaxy\n",
    "             \n",
    "             Args:\n",
    "                 self : refers to the class\n",
    "                 path : Where the image is stored\n",
    "                 label : The image name \n",
    "                 answer : The final answer (smooth or spiral). This is the answer from the data set. \n",
    "                          It is used to verify after making a decision. \n",
    "                          \n",
    "              Returns:\n",
    "                  An Image object with the image manipulations\n",
    "         \"\"\"\n",
    "        self.Path = path\n",
    "        self.Label = label\n",
    "        self.Answer = answer\n",
    "        self.Pixels = np.array(cv.imread(path))\n",
    "        self.Width = self.Pixels.shape[0]\n",
    "        self.Hight = self.Pixels.shape[1]\n",
    "        #we will always use the cropped image\n",
    "        #default crop is 250\n",
    "        self.crop(self.Width)\n",
    "        #useful image manipulations\n",
    "        self.manipulations()\n",
    "        #default computations\n",
    "        self.ComputeCircularity()\n",
    "        self.computeBlackWhite()\n",
    "        self.ComputeConvexity()\n",
    "        self.ComputeBoundingRectangleToFillFactor()\n",
    "        \n",
    "    def manipulations(self):\n",
    "        \"\"\"\n",
    "             This method is used to apply all the images manipulation on the image. Such as grayscale.\n",
    "             Cropped image is the default image used \n",
    "             \n",
    "             Args:\n",
    "                 self: refers to the class\n",
    "        \"\"\"\n",
    "        #remove noise by blurring with a Gaussian filter\n",
    "        self.CroppedPixels = cv.GaussianBlur(self.CroppedPixels,(3,3), 0)\n",
    "        #convert to grayscale\n",
    "        self.GrayScale = cv.cvtColor(self.CroppedPixels, cv.COLOR_BGR2GRAY)\n",
    "        \"\"\"remove background noise\n",
    "        #the result is worst with laplacian\n",
    "        #laplacian = cv.Laplacian(self._GrayScale, cv.CV_16S, 3)\n",
    "        #laplacian = cv.convertScaleAbs(laplacian)\n",
    "        #self._GrayScale = self._GrayScale - laplacian \n",
    "        \"\"\"\n",
    "        self.Threshold = threshold_otsu(self.GrayScale)\n",
    "        self.Binary = self.GrayScale > self.Threshold\n",
    "    \n",
    "    def crop(self, dimentions):\n",
    "        \"\"\"\n",
    "             This method is used to apply a crop to the image. Since the image is squared only on parameter is required \n",
    "             \n",
    "             Args:\n",
    "                 dimentions: refers the final demention of the image. Such as the final image would have\n",
    "                                 dimentions*dimentions. Ex: dimentions=250 the image will be 250x250\n",
    "        \"\"\"\n",
    "        # dimention is the width and hight to crop to. Since it is a square.\n",
    "        upper_width = int(self.Width/2 + dimentions/2)\n",
    "        lower_width = int(self.Width/2 - dimentions/2)\n",
    "        upper_height = int(self.Hight/2 + dimentions/2)\n",
    "        lower_height = int(self.Hight/2 - dimentions/2)\n",
    "        #new array of the image\n",
    "        self.CroppedPixels = self.Pixels[ lower_width:upper_width,lower_height : upper_height]\n",
    "        \n",
    "    def computeBlackWhite(self):\n",
    "        \"\"\"\n",
    "             This method is used to compute the black and white ratio.\n",
    "             The formula is blacks / whites\n",
    "             \n",
    "             Args:\n",
    "                 self: refers to the class\n",
    "        \"\"\"\n",
    "        self.Black = 0\n",
    "        self.White = 0\n",
    "        self.BlackWhiteRatio = 0\n",
    "        #compute the # of black and the # of whites\n",
    "        for row in self.Binary :\n",
    "            for pixel in row:\n",
    "                if(pixel):\n",
    "                    self.White += 1\n",
    "                else:\n",
    "                    self.Black += 1\n",
    "        #compute the B/W ratio\n",
    "        if self.Black > 0 and self.White >0 :\n",
    "            self.BlackWhiteRatio = self.Black / self.White\n",
    "        \n",
    "    def ComputeCircularity(self):\n",
    "        \"\"\"\n",
    "             This method is used to compute the circularity of the galaxy.\n",
    "             The formula used is : ùê∂ = 4 ‚àó ùúã ‚àó ùê¥/ùëÉ2\n",
    "             \n",
    "             Args:\n",
    "                 self: refers to the class\n",
    "         \"\"\"\n",
    "        #example from openCV documentation\n",
    "        ret,thresh = cv.threshold(self.GrayScale,self.Threshold, 255, 0)\n",
    "        img, contours, hierarchy = cv.findContours(thresh,1 ,2 )\n",
    "        self.cnt = contours[0]\n",
    "        \n",
    "        self.area = cv.contourArea(self.cnt)\n",
    "        self.perimeter = cv.arcLength(self.cnt,True)\n",
    "        #circularity\n",
    "        self.C = 0\n",
    "        if self.area >0 and self.perimeter > 0 :\n",
    "            self.FormFactor = self.area/ math.pow(self.perimeter,2)\n",
    "            self.C = 4* math.pi * self.FormFactor \n",
    "    \n",
    "    def ComputeConvexity(self):\n",
    "        \"\"\"\n",
    "             This method is used to compute the convexity of the galaxy.\n",
    "             The formula used is : ùê∂ = P / (2W + 2H)\n",
    "             where P is the perimeter\n",
    "             W is the width of the bounding rectangle\n",
    "             H is the height of the bounding rectangle\n",
    "             \n",
    "             Args:\n",
    "                 self: refers to the class\n",
    "         \"\"\"\n",
    "        x,y,w,h = cv.boundingRect(self.cnt)\n",
    "        self.Convexity = self.perimeter / (2*w+2*h)\n",
    "\n",
    "    def ComputeBoundingRectangleToFillFactor(self):\n",
    "        \"\"\"\n",
    "             This method is used to compute the bounding rectangle to fill factor.\n",
    "             The formula used is : B = A / (W*H)\n",
    "             Where is A is the area of the shape\n",
    "             W*H is the area of the bounding rectangle\n",
    "             Args:\n",
    "                 self: refers to the class\n",
    "         \"\"\"\n",
    "        x,y,w,h = cv.boundingRect(self.cnt)\n",
    "        self.B = self.area / (w*h)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAllImages(dataPath , imageFolderPath):\n",
    "    \"\"\"\n",
    "             This method is used to al the images from the data set.\n",
    "             \n",
    "             Args:\n",
    "                 dataPath: the dataset file path\n",
    "                 imageFolderPath: the image dataset folder path\n",
    "         \"\"\"\n",
    "    dataFile = open(dataPath, 'r') # option r veut dire read\n",
    "    #index is used to load a define number of images.\n",
    "    index = 0\n",
    "    for line in dataFile:\n",
    "        texts = line.split(\",\")\n",
    "        imageName = texts[0]\n",
    "        shape = str(texts[1])\n",
    "\n",
    "        imagePath = imageFolderPath +\"\\\\\"+str(imageName)+'.jpg'\n",
    "        if index < 200 and \"smooth\" in line:\n",
    "            index += 1\n",
    "            if index % 10 <= 7:\n",
    "                trainDataSet.append(Image(imagePath,imageName,shape))\n",
    "            else:\n",
    "                testDataSet.append(Image(imagePath,imageName,shape))\n",
    "        elif index >= 200 and index < 400 and \"spiral\" in line:\n",
    "            index += 1\n",
    "            if index % 10 <= 7:\n",
    "                trainDataSet.append(Image(imagePath,imageName,shape))\n",
    "            else:\n",
    "                testDataSet.append(Image(imagePath,imageName,shape))\n",
    "\n",
    "    dataFile.close()\n",
    "    \n",
    "def  traceGraph(feature1x, feature1y, feature1Name, feature2x, feature2y, feature2Name, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "         This method is used to out a 2D graph with the selected features\n",
    "\n",
    "         Args:\n",
    "             feature1x : The feature 1 x array. It will be used for the first data set shown in the graph. \n",
    "             feature1y : The feature 1 y array. It will be used for the first data set shown in the graph.\n",
    "             feature1Name : The feature 1 dataset name. It will be used for the first data set shown in the graph.\n",
    "             feature2x : The feature 2 x array. It will be used for the first data set shown in the graph.\n",
    "             feature2y : The feature 2yx array. It will be used for the first data set shown in the graph.\n",
    "             feature2Name : The feature 2 dataset name. It will be used for the first data set shown in the graph.\n",
    "             xlabel : the label shown on the x axis.\n",
    "             ylabel: the label shown on the y axis:\n",
    "     \"\"\"\n",
    "    #fig = plt.figure()\n",
    "    #ax1 = fig.add_subplot()\n",
    "    plt.grid(True)\n",
    "    plt.scatter(feature1x, feature1y, s=10, c='b', marker=\"s\", label=feature1Name)\n",
    "    plt.scatter(feature2x, feature2y, s=10, c='r', marker=\"o\", label=feature2Name)\n",
    "    plt.ylabel(xlabel)\n",
    "    plt.xlabel(ylabel)\n",
    "    plt.legend(loc='upper left');\n",
    "    plt.show()\n",
    "\n",
    "def buildTree(trainArray):\n",
    "    \"\"\"\n",
    "        This method is used to build the decision tree and how the graph associated with it.\n",
    "        fit(x,y) takes two arrays:\n",
    "        X, sparse or dense, of size [n_samples, n_features] holding the training samples, and an array \n",
    "                ex: [[0, 0], [1, 1]]\n",
    "        Y of integer values, size [n_samples], holding the class labels \n",
    "             ex : [0, 1]\n",
    "        \n",
    "        Since out Y array is not numerical we are using preprocessing fron sklearn to transforme them\n",
    "        Args:\n",
    "            trainArray: the array containing all the features. It will be used as the X\n",
    "     \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([\"smooth\",\"spiral\"])\n",
    "    y = le.transform([\"smooth\",\"spiral\"])\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(trainArray, y)\n",
    "    dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "    graph = graphviz.Source(dot_data) \n",
    "    graph.render(\"Galaxy\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  52\n",
      "circularity:  0.34290273015491973\n",
      "black  171868\n",
      "white  7908\n",
      "B/W ratio:  21.73343449671219\n",
      "convexity:  0.6178511281808218\n",
      "8 Bounding rectangle to fill factor:  0.1875\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "img = Image(\"C:\\\\Users\\\\ThinkPad\\\\Downloads\\\\gti770\\\\data\\\\images\\\\231792.jpg\",\"232031\",\"smooth\")\n",
    "\n",
    "#plt.imshow(img.CroppedPixels)\n",
    "#plt.title(\"original\")\n",
    "#plt.show()\n",
    "\n",
    "#plt.imshow(img.GrayScale)\n",
    "#plt.title(\"grayscale\")\n",
    "#plt.show()\n",
    "\n",
    "print(\"threshold: \",img.Threshold)\n",
    "#plt.imshow(img.Binary)\n",
    "#plt.title(\"binarized\")\n",
    "#plt.show()\n",
    "\n",
    "print(\"circularity: \", img.C)\n",
    "\n",
    "print(\"black \",img.Black)\n",
    "print(\"white \", img.White)\n",
    "print(\"B/W ratio: \", img.BlackWhiteRatio)\n",
    "\n",
    "print(\"convexity: \", img.Convexity)\n",
    "print(\"8 Bounding rectangle to fill factor: \", img.B)\n",
    "#load\n",
    "#sepration 70%-30% of the data set\n",
    "trainDataSet = []\n",
    "testDataSet = []\n",
    "\n",
    "\n",
    "loadAllImages(\"C:\\\\Users\\\\ThinkPad\\\\Downloads\\\\gti770\\\\data\\\\csv\\\\galaxy\\\\galaxy_label_data_set.csv\",\"C:\\\\Users\\\\ThinkPad\\\\Downloads\\\\gti770\\\\data\\\\images\")\n",
    "#B/W ratio\n",
    "feature1x = []\n",
    "feature1y = []\n",
    "#circularity\n",
    "feature2x = []\n",
    "feature2y = []\n",
    "#convexity\n",
    "feature3x = []\n",
    "feature3y = []\n",
    "#Bounding factor\n",
    "feature4x = []\n",
    "feature4y = []\n",
    "\n",
    "trainArray= []\n",
    "\n",
    "for ig in trainDataSet:\n",
    "    trainArray.append([ig.BlackWhiteRatio, ig.C, ig.Convexity, ig.B])\n",
    "    if\"smooth\" in ig.Answer:\n",
    "        feature1x.append(ig.BlackWhiteRatio)\n",
    "        feature1y.append(ig.C)\n",
    "        feature3x.append(ig.Convexity)\n",
    "        feature3y.append(ig.B)\n",
    "    else:\n",
    "        feature2x.append(ig.BlackWhiteRatio)\n",
    "        feature2y.append(ig.C)\n",
    "        feature4x.append(ig.Convexity)\n",
    "        feature4y.append(ig.B)\n",
    "\"\"\"for ig in testDataSet:\n",
    "    if\"smooth\" in ig.Answer:\n",
    "        feature1x.append(ig.BlackWhiteRatio)\n",
    "        feature1y.append(ig.C)\n",
    "    else:\n",
    "        feature2x.append(ig.BlackWhiteRatio)\n",
    "        feature2y.append(ig.C)\n",
    "\"\"\"\n",
    "\n",
    "traceGraph(feature1x,feature1y,\"smooth\",feature2x,feature2y,\"spiral\", \"Black/White ratio\", \"Circularity\")\n",
    "traceGraph(feature3x,feature3y,\"smooth\",feature4x,feature4y,\"spiral\", \"Convexitry\", \"Bounding ratio\")\n",
    "\n",
    "buildTree(trainArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction et revue de la litt√©rature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dans le cadre de ce laboratoire, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliographie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-214-1f74ff1184fd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-214-1f74ff1184fd>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    https://docs.opencv.org/3.4.2/dd/d49/tutorial_py_contour_features.html\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://docs.opencv.org/3.4.2/dd/d49/tutorial_py_contour_features.html\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
