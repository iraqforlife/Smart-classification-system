{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 2 : Arbre de désision, Bayes naïf et KNN\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             |                                                         |\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Jean-Philippe Decoste |  DECJ19059105                                           |\n",
    "| Ahmad Al-Taher        |   ALTA22109307                                          |\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Automne 2018                                            |\n",
    "| Groupe                | 2                                                       |\n",
    "| Numéro du laboratoire | 02                                                      |\n",
    "| Professeur            | Hervé Lombaert                                          |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 30 oct 2018                                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes et librairies utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from image import Image as imageObj\n",
    "from imageV2 import Image as imageFeat\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from spam import Spam\n",
    "import utilities\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramètres de l'application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAB01\n",
    "IMAGE_CSV_NAME = r\"data\\csv\\galaxy\\galaxy_label_data_set.csv\"\n",
    "IMAGETEST_CSV_NAME = r\"data\\csv\\galaxy\\galaxy_label_data_set_test.csv\"\n",
    "\n",
    "#Galaxy features\n",
    "EXTRATED_GALAXY_PRIMITIVE = r\"data\\csv\\eq07_pExtraction.csv\"\n",
    "MERGED_GALAXY_PRIMITIVE = r\"data\\csv\\eq07_pMerged.csv\"\n",
    "ALL_GALAXY_PRIMITIVE = r\"data\\csv\\galaxy\\galaxy_feature_vectors.csv\"\n",
    "\n",
    "#Spam features\n",
    "ALL_SPAM_PRIMITIVE = r\"data\\csv\\spam\\spam.csv\"\n",
    "\n",
    "#Algo params\n",
    "TREE_DEPTH = [None, 3, 5, 10]\n",
    "EXTRACT_TREE_PDF = False\n",
    "N_NEIGHBORS = [3, 5, 10]\n",
    "WEIGHTS = ['uniform', 'distance']\n",
    "\n",
    "#General config\n",
    "PRIMITIVE_SCANNING = True\n",
    "DOMERGE = False\n",
    "PRINT_GRAPH = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree():\n",
    "    \"\"\"\n",
    "    This method is used to build the decision tree and how the graph associated with it.\n",
    "    fit(x,y) takes two arrays:\n",
    "    X, sparse or dense, of size [n_samples, n_features] holding the training samples, and an array\n",
    "            ex: [[0, 0], [1, 1]]\n",
    "    Y of integer values, size [n_samples], holding the class labels\n",
    "            ex : [0, 1]\n",
    "\n",
    "    Since out Y array is not numerical we are using preprocessing from klearn to transform them\n",
    "    Args:\n",
    "        data: the array containing all the features. It will be used as the X\n",
    "        labels: the array containing all the labels. It will be used as the Y\n",
    "    \"\"\"\n",
    "    print(\"1.Training with Holdout\\n\")\n",
    "    dTreePerf = [['Depth', 'Accuracy', 'Precision', 'F1']]\n",
    "    params = dict(max_depth=TREE_DEPTH)\n",
    "    holdoutValidation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    grid = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv=holdoutValidation, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "   \n",
    "    #Fit data to Decision Tree algo\n",
    "    grid.fit(features, answers)\n",
    "\n",
    "    #Loop through results\n",
    "    for i in range(0, 4):\n",
    "        dTreePerf.append([grid.cv_results_['params'][i]['max_depth'],\n",
    "                          \"{0:.2f}\".format(grid.cv_results_['mean_test_accuracy'][i]*100),\n",
    "                          \"{0:.2f}\".format(grid.cv_results_['mean_test_precision'][i]*100),\n",
    "                          \"{0:.2f}\".format(grid.cv_results_['mean_test_f1'][i]*100)])\n",
    "        \n",
    "    utilities.traceGraph([0, 2, 4, 6, 8, 10],TREE_DEPTH,'Profondeur',[0, .2,.4,.6,.8,1],TREE_DEPTH,'Pourcentage','k','accuracy', \"accuracy/K\")\n",
    "\n",
    "    print(tabulate(dTreePerf, headers=\"firstrow\"))\n",
    "    print(\"\\nThe best is depth = %s\" %(grid.best_params_['max_depth']))\n",
    "    \n",
    "    print(\"\\n2.Training best params with 5-fold cross-validation\\n\")\n",
    "    dTreePerf = [['Depth', 'Accuracy', 'Precision', 'F1']]\n",
    "    params = dict(max_depth=[grid.best_params_['max_depth']])\n",
    "    bestGrid = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv=5, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "    \n",
    "    #Fit data to Decision Tree algo\n",
    "    bestGrid.fit(features, answers)\n",
    "    \n",
    "    dTreePerf.append([bestGrid.cv_results_['params'][0]['max_depth'],\n",
    "                      \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_accuracy'][0]*100),\n",
    "                      \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_precision'][0]*100),\n",
    "                      \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_f1'][0]*100)])\n",
    "    \n",
    "    print(tabulate(dTreePerf, headers=\"firstrow\"))\n",
    "    print(\"-> Done\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn():\n",
    "    print(\"1.Training with Holdout\\n\")\n",
    "    knnPerf = [['Weights', 'K', 'Accuracy', 'Precision', 'F1']]\n",
    "    params = dict(n_neighbors=N_NEIGHBORS, weights=WEIGHTS, algorithm=['auto'])\n",
    "    holdoutValidation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid=params, cv=holdoutValidation, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "\n",
    "    #Fit data to knn algo\n",
    "    grid.fit(features, answers)\n",
    "\n",
    "    #Loop through results\n",
    "    for i in range(0, 6):\n",
    "        knnPerf.append([grid.cv_results_['params'][i]['weights'],\n",
    "                        grid.cv_results_['params'][i]['n_neighbors'],\n",
    "                        \"{0:.2f}\".format(grid.cv_results_['mean_test_accuracy'][i]*100),\n",
    "                        \"{0:.2f}\".format(grid.cv_results_['mean_test_precision'][i]*100),\n",
    "                        \"{0:.2f}\".format(grid.cv_results_['mean_test_f1'][i]*100)])\n",
    "\n",
    "    print(tabulate(knnPerf, headers=\"firstrow\"))\n",
    "    print(\"\\nThe best is KNN %s With K = %s\" %(grid.best_params_['weights'], grid.best_params_['n_neighbors']))\n",
    "    \n",
    "    print(\"\\n2.Training best params with 5-fold cross-validation\\n\")\n",
    "    knnPerf = [['Weights', 'K', 'Accuracy', 'Precision', 'F1']]\n",
    "    params = dict(n_neighbors=[grid.best_params_['n_neighbors']], weights=[grid.best_params_['weights']], algorithm=['auto'])\n",
    "    bestGrid = GridSearchCV(KNeighborsClassifier(), param_grid=params, cv=5, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "    \n",
    "    #Fit data to knn algo\n",
    "    bestGrid.fit(features, answers)\n",
    "    \n",
    "    knnPerf.append([bestGrid.cv_results_['params'][0]['weights'],\n",
    "                    bestGrid.cv_results_['params'][0]['n_neighbors'],\n",
    "                    \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_accuracy'][0]*100),\n",
    "                    \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_precision'][0]*100),\n",
    "                    \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_f1'][0]*100)])\n",
    "    \n",
    "    print(tabulate(knnPerf, headers=\"firstrow\"))\n",
    "    print(\"-> Done\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes (MultinomialMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes():\n",
    "    print(\"1.Training with Holdout\\n\")\n",
    "    bayesPerf = [['Data type', 'Accuracy', 'Precision', 'F1']]\n",
    "    params = dict()\n",
    "    holdoutValidation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    grid = GridSearchCV(MultinomialNB(), param_grid=params, cv=holdoutValidation, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "\n",
    "    #Scale the data between 0 and 1\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(features)\n",
    "    xNormalized = scaler.transform(features)\n",
    "\n",
    "    #Fit normalized data to Bayes algo\n",
    "    grid.fit(xNormalized, answers)\n",
    "    bayesPerf.append(['Normalized',\n",
    "                      \"{0:.2f}\".format(float(grid.cv_results_['mean_test_accuracy'])*100),\n",
    "                      \"{0:.2f}\".format(float(grid.cv_results_['mean_test_precision'])*100),\n",
    "                      \"{0:.2f}\".format(float(grid.cv_results_['mean_test_f1'])*100)])\n",
    "    normalizedResult = float(grid.cv_results_['mean_test_accuracy'])\n",
    "    \n",
    "    #Discretize normalized data\n",
    "    est = preprocessing.KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "    est.fit(features)\n",
    "    xKBinsDiscretizer = est.transform(features)\n",
    "\n",
    "    #Fit discretize data to bayes algorithm\n",
    "    grid.fit(xKBinsDiscretizer, answers)\n",
    "    bayesPerf.append(['Discretized',\n",
    "                        \"{0:.2f}\".format(float(grid.cv_results_['mean_test_accuracy'])*100),\n",
    "                        \"{0:.2f}\".format(float(grid.cv_results_['mean_test_precision'])*100),\n",
    "                        \"{0:.2f}\".format(float(grid.cv_results_['mean_test_f1'])*100)])\n",
    "    discretizedResult = float(grid.cv_results_['mean_test_accuracy'])\n",
    "    \n",
    "    print(tabulate(bayesPerf, headers=\"firstrow\"))\n",
    "    \n",
    "    print(\"\\n2.Training best params with 5-fold cross-validation\\n\")\n",
    "    bayesPerf = [['Data type', 'Accuracy', 'Precision', 'F1']]\n",
    "    params = dict()\n",
    "    bestGrid = GridSearchCV(MultinomialNB(), param_grid=params, cv=5, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "    \n",
    "    #Fit data to Bayes algo\n",
    "    if normalizedResult > discretizedResult:\n",
    "        bestGrid.fit(xNormalized, answers)\n",
    "    else:\n",
    "        bestGrid.fit(xKBinsDiscretizer, answers)\n",
    "    \n",
    "    bayesPerf.append(['Discretized',\n",
    "                        \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_accuracy'])*100),\n",
    "                        \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_precision'])*100),\n",
    "                        \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_f1'])*100)])\n",
    "    \n",
    "    print(tabulate(bayesPerf, headers=\"firstrow\"))\n",
    "    print(\"-> Done\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab2_prepareDataset(datasetName, dataset):\n",
    "    print(\"PREPARING DATASETS\")\n",
    "    allData_length = len(list(csv.reader(open(dataset))))\n",
    "    progress = 0\n",
    "    datas = []\n",
    "\n",
    "    print(\"Reading \" + datasetName + \" features:\")\n",
    "    utilities.printProgressBar(0, allData_length, prefix='Progress:', suffix='Complete', length=50)\n",
    "    with open(dataset, 'r') as theFile:\n",
    "        primitives = csv.reader(theFile, delimiter=',', quotechar='|')\n",
    "\n",
    "        for row in primitives:\n",
    "            progress += 1\n",
    "            utilities.printProgressBar(progress+1, allData_length, prefix='Progress', suffix='Complete', length=50)\n",
    "\n",
    "            values = [float(i) for i in row]\n",
    "            if datasetName == \"Galaxy\":\n",
    "                datas.append(imageFeat(values))\n",
    "            elif datasetName == \"Spam\":\n",
    "                datas.append(Spam(values))\n",
    "    print(\"\\n-> Done\\n\")\n",
    "\n",
    "    #3. Split dataset using model_selection\n",
    "    for data in np.array(datas):\n",
    "        features.append(data.features)\n",
    "        answers.append(data.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING DATASETS\n",
      "Reading Galaxy features:\n",
      "Progress |**************************************************| 100.0% Complete\n",
      "-> Done\n",
      "\n",
      "ALGORITHMS\n",
      "\n",
      "Decision Tree:\n",
      "1.Training with Holdout\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-780521bc0dfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#2.1. DECISION TREE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nDecision Tree:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#2.2. KNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"KNN:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-b16f91b8fee3>\u001b[0m in \u001b[0;36mdecisionTree\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m                           \"{0:.2f}\".format(grid.cv_results_['mean_test_f1'][i]*100)])\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mutilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTREE_DEPTH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Profondeur'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTREE_DEPTH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Pourcentage'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"accuracy/K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdTreePerf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"firstrow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ETS\\A2018\\GTI770\\gti770\\utilities.py\u001b[0m in \u001b[0;36mtraceGraph\u001b[1;34m(self, feature1x, feature1y, feature1Name, feature2x, feature2y, feature2Name, xlabel, ylabel)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;31m#ax1 = fig.add_subplot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature1x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature1y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature1Name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature2x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature2y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"o\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature2Name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gti770_env\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[0;32m   2791\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2792\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2793\u001b[1;33m         verts=verts, edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[0;32m   2794\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2795\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gti770_env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1783\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1785\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gti770_env\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[0;32m   4163\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4165\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#0. Generate new feature files for Galaxy (only run once)\n",
    "#utilities.lab1_extractFeatures()\n",
    "\n",
    "#1.A Read Galaxy features (name of file, path, n_split, test size, random state)\n",
    "features = []\n",
    "answers = []\n",
    "if os.path.isfile(MERGED_GALAXY_PRIMITIVE):\n",
    "    lab2_prepareDataset(\"Galaxy\", MERGED_GALAXY_PRIMITIVE)\n",
    "else:\n",
    "    lab2_prepareDataset(\"Galaxy\", ALL_GALAXY_PRIMITIVE)\n",
    "\n",
    "#2.A Execute Algorithm\n",
    "print(\"ALGORITHMS\")\n",
    "#2.1. DECISION TREE\n",
    "print(\"\\nDecision Tree:\")\n",
    "decisionTree()\n",
    "#2.2. KNN\n",
    "print(\"KNN:\")\n",
    "knn()\n",
    "#2.3. BAYES\n",
    "print(\"\\nBayes MultinomialNB\")\n",
    "bayes()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#3.B Read Spams features (name of file, path, n_split, test size, random state)\n",
    "features = []\n",
    "answers = []\n",
    "lab2_prepareDataset(\"Spam\", ALL_SPAM_PRIMITIVE)\n",
    "\n",
    "#4.B Execute Algorithm\n",
    "print(\"ALGORITHMS\")\n",
    "#4.1. DECISION TREE\n",
    "print(\"\\nDecision Tree:\")\n",
    "decisionTree()\n",
    "#4.2. KNN\n",
    "print(\"KNN:\")\n",
    "knn()\n",
    "#4.3. BAYES\n",
    "print(\"\\nBayes MultinomialNB\")\n",
    "bayes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*to delete\n",
    "résultat des algo sans rajouté de nos premitive\n",
    "KNN uniform has a score of 0.68 with k=3 \n",
    "KNN distance has a score of 0.69 with k=3 \n",
    "KNN uniform has a score of 0.64 with k=5 \n",
    "KNN distance has a score of 0.65 with k=5 \n",
    "KNN uniform has a score of 0.69 with k=10 \n",
    "KNN distance has a score of 0.67 with k=10 \n",
    "The best parameters are {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} with a score of 0.69\n",
    "MultinomialNB with normalized values best score is 0.89\n",
    "MultinomialNB with discretized values best score is 0.77\n",
    "Working with the images\n",
    "KNN uniform has a score of 0.61 with k=3 \n",
    "KNN distance has a score of 0.59 with k=3 \n",
    "KNN uniform has a score of 0.62 with k=5 \n",
    "KNN distance has a score of 0.60 with k=5 \n",
    "KNN uniform has a score of 0.62 with k=10 \n",
    "KNN distance has a score of 0.63 with k=10 \n",
    "The best parameters are {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} with a score of 0.63\n",
    "MultinomialNB with normalized values best score is 0.71\n",
    "MultinomialNB with discretized values best score is 0.71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Méthode de création des ensembles de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Détails des ensembles produits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### Approche de validation proposée et justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Matrice des expérimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Étude des hyperparamètres et des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "### Impact de la taille des ensembles de données sur la performance de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "### Impact du bruit dans les ensembles de données sur la performance de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "### Discussion sur la nature des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "### Recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "### Améliorations possibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
