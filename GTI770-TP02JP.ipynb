{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 2 : Arbre de désision, Bayes naïf et KNN\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             |                                                         |\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Jean-Philippe Decoste |  DECJ19059105                                           |\n",
    "| Ahmad Al-Taher        |   ALTA22109307                                          |\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Automne 2018                                            |\n",
    "| Groupe                | 2                                                       |\n",
    "| Numéro du laboratoire | 02                                                      |\n",
    "| Professeur            | Hervé Lombaert                                          |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 30 oct 2018                                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes et librairies utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from image import Image as imageObj\n",
    "from imageV2 import Image as imageFeat\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from spam import Spam\n",
    "import utilities\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramètres de l'application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAB01\n",
    "IMAGE_CSV_NAME = r\"data\\csv\\galaxy\\galaxy_label_data_set.csv\"\n",
    "IMAGETEST_CSV_NAME = r\"data\\csv\\galaxy\\galaxy_label_data_set_test.csv\"\n",
    "\n",
    "#Galaxy features\n",
    "EXTRATED_GALAXY_PRIMITIVE = r\"data\\csv\\eq07_pExtraction.csv\"\n",
    "MERGED_GALAXY_PRIMITIVE = r\"data\\csv\\eq07_pMerged.csv\"\n",
    "ALL_GALAXY_PRIMITIVE = r\"tp02.csv\"\n",
    "\n",
    "#Spam features\n",
    "ALL_SPAM_PRIMITIVE = r\"spam.csv\"\n",
    "\n",
    "#Algo params\n",
    "TREE_DEPTH = [None, 3, 5, 10]\n",
    "EXTRACT_TREE_PDF = False\n",
    "N_NEIGHBORS = [3, 5, 10]\n",
    "WEIGHTS = ['uniform', 'distance']\n",
    "VALIDATION_METHOD = ['Holdout', 'Stratified Shuffle Split']\n",
    "\n",
    "#General config\n",
    "PRIMITIVE_SCANNING = True\n",
    "DOMERGE = False\n",
    "PRINT_GRAPH = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree():\n",
    "    \"\"\"\n",
    "    Algorithme 'Decision Tree' utilisé pour classer les données qui lui sont fourni\n",
    "    Args:\n",
    "        --\n",
    "    \"\"\"\n",
    "    validationCounter = 1\n",
    "    for method in VALIDATION_METHOD:\n",
    "        validation =  None\n",
    "        if method == 'Holdout':\n",
    "            validation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "        elif method == 'Stratified Shuffle Split':\n",
    "            validation = StratifiedShuffleSplit()\n",
    "        \n",
    "        print(str(validationCounter)+\".Training with \"+method+\"\\n\")\n",
    "        dTreePerf = [['Depth', 'Accuracy', 'Precision', 'F1']]\n",
    "        params = dict(max_depth=TREE_DEPTH)\n",
    "        grid = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv=validation, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "\n",
    "        #Fit data to Decision Tree algo\n",
    "        grid.fit(features, answers)\n",
    "\n",
    "        #Loop through results\n",
    "        for i in range(0, 4):\n",
    "            dTreePerf.append([grid.cv_results_['params'][i]['max_depth'],\n",
    "                              \"{0:.2f}\".format(grid.cv_results_['mean_test_accuracy'][i]*100),\n",
    "                              \"{0:.2f}\".format(grid.cv_results_['mean_test_precision'][i]*100),\n",
    "                              \"{0:.2f}\".format(grid.cv_results_['mean_test_f1'][i]*100)])\n",
    "\n",
    "        print(tabulate(dTreePerf, headers=\"firstrow\"))\n",
    "        print(\"\\nThe best is depth = %s\" %(grid.best_params_['max_depth']))\n",
    "        print()\n",
    "        validationCounter += 1\n",
    "    \n",
    "    print(str(validationCounter)+\".Training best params with 5-fold cross-validation\\n\")\n",
    "    dTreePerf = [['Depth', 'Accuracy', 'Precision', 'F1']]\n",
    "    params = dict(max_depth=[grid.best_params_['max_depth']])\n",
    "    bestGrid = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv=10, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "    \n",
    "    #Fit data to Decision Tree algo\n",
    "    bestGrid.fit(features, answers)\n",
    "    \n",
    "    dTreePerf.append([bestGrid.cv_results_['params'][0]['max_depth'],\n",
    "                      \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_accuracy'][0]*100),\n",
    "                      \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_precision'][0]*100),\n",
    "                      \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_f1'][0]*100)])\n",
    "    \n",
    "    print(tabulate(dTreePerf, headers=\"firstrow\"))\n",
    "    print(\"-> Done\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn():\n",
    "    \"\"\"\n",
    "    Algorithme 'KNN' utilisé pour classer les données qui lui sont fourni\n",
    "    Args:\n",
    "        --\n",
    "    \"\"\"\n",
    "    validationCounter = 1\n",
    "    for method in VALIDATION_METHOD:\n",
    "        validation =  None\n",
    "        if method == 'Holdout':\n",
    "            validation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "        elif method == 'Stratified Shuffle Split':\n",
    "            validation = StratifiedShuffleSplit()\n",
    "            \n",
    "        print(str(validationCounter)+\".Training with \"+method+\"\\n\")\n",
    "        knnPerf = [['Weights', 'K', 'Accuracy', 'Precision', 'F1']]\n",
    "        params = dict(n_neighbors=N_NEIGHBORS, weights=WEIGHTS, algorithm=['auto'])\n",
    "        holdoutValidation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "        grid = GridSearchCV(KNeighborsClassifier(), param_grid=params, cv=validation, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "\n",
    "        #Fit data to knn algo\n",
    "        grid.fit(features, answers)\n",
    "\n",
    "        #Loop through results\n",
    "        for i in range(0, 6):\n",
    "            knnPerf.append([grid.cv_results_['params'][i]['weights'],\n",
    "                            grid.cv_results_['params'][i]['n_neighbors'],\n",
    "                            \"{0:.2f}\".format(grid.cv_results_['mean_test_accuracy'][i]*100),\n",
    "                            \"{0:.2f}\".format(grid.cv_results_['mean_test_precision'][i]*100),\n",
    "                            \"{0:.2f}\".format(grid.cv_results_['mean_test_f1'][i]*100)])\n",
    "\n",
    "        print(tabulate(knnPerf, headers=\"firstrow\"))\n",
    "        print(\"\\nThe best is KNN %s With K = %s\" %(grid.best_params_['weights'], grid.best_params_['n_neighbors']))\n",
    "        print()\n",
    "        validationCounter += 1\n",
    "    \n",
    "    print(\"\\n\"+str(validationCounter)+\".Training best params with 5-fold cross-validation\\n\")\n",
    "    knnPerf = [['Weights', 'K', 'Accuracy', 'Precision', 'F1']]\n",
    "    params = dict(n_neighbors=[grid.best_params_['n_neighbors']], weights=[grid.best_params_['weights']], algorithm=['auto'])\n",
    "    bestGrid = GridSearchCV(KNeighborsClassifier(), param_grid=params, cv=10, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "    \n",
    "    #Fit data to knn algo\n",
    "    bestGrid.fit(features, answers)\n",
    "    \n",
    "    knnPerf.append([bestGrid.cv_results_['params'][0]['weights'],\n",
    "                    bestGrid.cv_results_['params'][0]['n_neighbors'],\n",
    "                    \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_accuracy'][0]*100),\n",
    "                    \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_precision'][0]*100),\n",
    "                    \"{0:.2f}\".format(bestGrid.cv_results_['mean_test_f1'][0]*100)])\n",
    "    \n",
    "    print(tabulate(knnPerf, headers=\"firstrow\"))\n",
    "    print(\"-> Done\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes (MultinomialMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes():\n",
    "    validationCounter = 1\n",
    "    for method in VALIDATION_METHOD:\n",
    "        validation =  None\n",
    "        if method == 'Holdout':\n",
    "            validation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "        elif method == 'Stratified Shuffle Split':\n",
    "            validation = StratifiedShuffleSplit()\n",
    "            \n",
    "        print(str(validationCounter)+\".Training with \"+method+\"\\n\")\n",
    "        bayesPerf = [['Data type', 'Accuracy', 'Precision', 'F1']]\n",
    "        params = dict()\n",
    "        holdoutValidation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "        grid = GridSearchCV(MultinomialNB(), param_grid=params, cv=validation, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "\n",
    "        #Scale the data between 0 and 1\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        scaler.fit(features)\n",
    "        xNormalized = scaler.transform(features)\n",
    "\n",
    "        #Fit normalized data to Bayes algo\n",
    "        grid.fit(xNormalized, answers)\n",
    "        bayesPerf.append(['Normalized',\n",
    "                          \"{0:.2f}\".format(float(grid.cv_results_['mean_test_accuracy'])*100),\n",
    "                          \"{0:.2f}\".format(float(grid.cv_results_['mean_test_precision'])*100),\n",
    "                          \"{0:.2f}\".format(float(grid.cv_results_['mean_test_f1'])*100)])\n",
    "        normalizedResult = float(grid.cv_results_['mean_test_accuracy'])\n",
    "\n",
    "        #Discretize normalized data\n",
    "        est = preprocessing.KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "        est.fit(features)\n",
    "        xKBinsDiscretizer = est.transform(features)\n",
    "\n",
    "        #Fit discretize data to bayes algorithm\n",
    "        grid.fit(xKBinsDiscretizer, answers)\n",
    "        bayesPerf.append(['Discretized',\n",
    "                            \"{0:.2f}\".format(float(grid.cv_results_['mean_test_accuracy'])*100),\n",
    "                            \"{0:.2f}\".format(float(grid.cv_results_['mean_test_precision'])*100),\n",
    "                            \"{0:.2f}\".format(float(grid.cv_results_['mean_test_f1'])*100)])\n",
    "        discretizedResult = float(grid.cv_results_['mean_test_accuracy'])\n",
    "\n",
    "        print(tabulate(bayesPerf, headers=\"firstrow\"))\n",
    "        if normalizedResult > discretizedResult:\n",
    "            print(\"\\nThe best is KNN %s With K = %s\" %(grid.best_params_['weights'], grid.best_params_['n_neighbors']))\n",
    "        print()\n",
    "        validationCounter += 1\n",
    "    \n",
    "    print(\"\\n\"+str(validationCounter)+\".Training best params with 5-fold cross-validation\\n\")\n",
    "    bayesPerf = [['Data type', 'Accuracy', 'Precision', 'F1']]\n",
    "    params = dict()\n",
    "    bestGrid = GridSearchCV(MultinomialNB(), param_grid=params, cv=10, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "    \n",
    "    #Fit data to Bayes algo    \n",
    "    bestGrid.fit(xNormalized, answers)\n",
    "    bayesPerf.append(['Normalize',\n",
    "                        \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_accuracy'])*100),\n",
    "                        \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_precision'])*100),\n",
    "                        \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_f1'])*100)])\n",
    "    \n",
    "    bestGrid.fit(xKBinsDiscretizer, answers)    \n",
    "    bayesPerf.append(['Discretized',\n",
    "                        \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_accuracy'])*100),\n",
    "                        \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_precision'])*100),\n",
    "                        \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_f1'])*100)])\n",
    "    \n",
    "    print(tabulate(bayesPerf, headers=\"firstrow\"))\n",
    "    print(\"-> Done\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes (GaussianMB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesGaussian():\n",
    "    validationCounter = 1\n",
    "    for method in VALIDATION_METHOD:\n",
    "        validation =  None\n",
    "        if method == 'Holdout':\n",
    "            validation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "        elif method == 'Stratified Shuffle Split':\n",
    "            validation = StratifiedShuffleSplit()\n",
    "            \n",
    "        print(str(validationCounter)+\".Training with \"+method+\"\\n\")\n",
    "        bayesPerf = [['Accuracy', 'Precision', 'F1']]\n",
    "        params = dict()\n",
    "        holdoutValidation = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "        grid = GridSearchCV(GaussianNB(), param_grid=params, cv=validation, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "\n",
    "        #Fit normalized data to Bayes algo\n",
    "        grid.fit(features, answers)\n",
    "        bayesPerf.append([\"{0:.2f}\".format(float(grid.cv_results_['mean_test_accuracy'])*100),\n",
    "                          \"{0:.2f}\".format(float(grid.cv_results_['mean_test_precision'])*100),\n",
    "                          \"{0:.2f}\".format(float(grid.cv_results_['mean_test_f1'])*100)])\n",
    "\n",
    "        print(tabulate(bayesPerf, headers=\"firstrow\"))\n",
    "    \n",
    "    print(\"\\n\"+str(validationCounter)+\".Training best params with 5-fold cross-validation\\n\")\n",
    "    bayesPerf = [['Accuracy', 'Precision', 'F1']]\n",
    "    params = dict()\n",
    "    bestGrid = GridSearchCV(GaussianNB(), param_grid=params, cv=10, n_jobs=-1, iid=True, scoring={'accuracy', 'precision', 'f1'}, refit='accuracy')\n",
    "    \n",
    "    #Fit data to Bayes algo\n",
    "    bestGrid.fit(features, answers)\n",
    "    \n",
    "    bayesPerf.append([\"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_accuracy'])*100),\n",
    "                      \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_precision'])*100),\n",
    "                      \"{0:.2f}\".format(float(bestGrid.cv_results_['mean_test_f1'])*100)])\n",
    "    \n",
    "    print(tabulate(bayesPerf, headers=\"firstrow\"))\n",
    "    print(\"-> Done\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab2_prepareDataset(datasetName, dataset):\n",
    "    print(\"PREPARING DATASETS\")\n",
    "    allData_length = len(list(csv.reader(open(dataset))))\n",
    "    progress = 0\n",
    "    datas = []\n",
    "\n",
    "    print(\"Reading \" + datasetName + \" features:\")\n",
    "    utilities.printProgressBar(0, allData_length, prefix='Progress:', suffix='Complete', length=50)\n",
    "    with open(dataset, 'r') as theFile:\n",
    "        primitives = csv.reader(theFile, delimiter=',', quotechar='|')\n",
    "\n",
    "        for row in primitives:\n",
    "            progress += 1\n",
    "            utilities.printProgressBar(progress+1, allData_length, prefix='Progress', suffix='Complete', length=50)\n",
    "\n",
    "            values = [float(i) for i in row]\n",
    "            if datasetName == \"Galaxy\":\n",
    "                datas.append(imageFeat(values))\n",
    "            elif datasetName == \"Spam\":\n",
    "                datas.append(Spam(values))\n",
    "    print(\"\\n-> Done\\n\")\n",
    "\n",
    "    #3. Split dataset using model_selection\n",
    "    for data in np.array(datas):\n",
    "        features.append(data.features)\n",
    "        answers.append(data.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0. Generate new feature files for Galaxy (only run once)\n",
    "#utilities.lab1_extractFeatures()\n",
    "\n",
    "#1.A Read Galaxy features (name of file, path, n_split, test size, random state)\n",
    "features = []\n",
    "answers = []\n",
    "if os.path.isfile(MERGED_GALAXY_PRIMITIVE):\n",
    "    lab2_prepareDataset(\"Galaxy\", MERGED_GALAXY_PRIMITIVE)\n",
    "else:\n",
    "    lab2_prepareDataset(\"Galaxy\", ALL_GALAXY_PRIMITIVE)\n",
    "\n",
    "#2.A Execute Algorithm\n",
    "print(\"ALGORITHMS\")\n",
    "#2.1. DECISION TREE\n",
    "print(\"\\nDecision Tree:\")\n",
    "decisionTree()\n",
    "#2.2. KNN\n",
    "print(\"KNN:\")\n",
    "knn()\n",
    "#2.3. BAYES\n",
    "print(\"\\nBayes MultinomialNB\")\n",
    "bayes()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#3.B Read Spams features (name of file, path, n_split, test size, random state)\n",
    "features = []\n",
    "answers = []\n",
    "lab2_prepareDataset(\"Spam\", ALL_SPAM_PRIMITIVE)\n",
    "\n",
    "#4.B Execute Algorithm\n",
    "print(\"ALGORITHMS\")\n",
    "#4.1. DECISION TREE\n",
    "print(\"\\nDecision Tree:\")\n",
    "decisionTree()\n",
    "#4.2. KNN\n",
    "print(\"KNN:\")\n",
    "knn()\n",
    "#4.3. BAYES\n",
    "print(\"\\nBayes MultinomialNB\")\n",
    "bayes()\n",
    "bayesGaussian()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "MultinomialNB with normalized values best score is 0.71\n",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Méthode de création des ensembles de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Détails des ensembles produits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### Approche de validation proposée et justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Matrice des expérimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Étude des hyperparamètres et des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "### Impact de la taille des ensembles de données sur la performance de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "### Impact du bruit dans les ensembles de données sur la performance de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "### Discussion sur la nature des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "### Recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "### Améliorations possibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
